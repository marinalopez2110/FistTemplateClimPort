{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import processing_netcdf as pcdf\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import shapely.geometry \n",
    "import numpy as np\n",
    "from shapely import geometry as gmty\n",
    "from geofeather import to_geofeather, from_geofeather\n",
    "import glob\n",
    "import os\n",
    "import pyarrow\n",
    "from xclim import ensembles as ens\n",
    "from xclim import subset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook only works for temperature\n",
    "- Average = tg_mean\n",
    "- Maximum = tx_mean\n",
    "- Minimum = tn_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Variable \n",
    "var = \"tn_mean\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all from here ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/ACCESS1-3_rcp45_tn_mean_seasonal.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/BNU-ESM_rcp45_tn_mean_seasonal.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/CanESM2_rcp45_tn_mean_seasonal.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/CMCC-CMS_rcp45_tn_mean_seasonal.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/GFDL-ESM2M_rcp45_tn_mean_seasonal.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/HadGEM2-CC_rcp45_tn_mean_seasonal.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/INM-CM4_rcp45_tn_mean_seasonal.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/IPSL-CM5A-LR_rcp45_tn_mean_seasonal.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/IPSL-CM5B-LR_rcp45_tn_mean_seasonal.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/MPI-ESM-LR_rcp45_tn_mean_seasonal.nc',\n",
       " '/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/NorESM1-M_rcp45_tn_mean_seasonal.nc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable85=\"rcp85_\"+var+\"_annual\"\n",
    "variable45=\"rcp45_\"+var+\"_annual\"\n",
    "#variable=\"rcp[48]5_tg_mean_annual\"\n",
    "\n",
    "files85 = glob.glob(folder+\"*\"+variable85+\".nc\")\n",
    "files45 = glob.glob(folder+\"*\"+variable45+\".nc\")\n",
    "#ex: ACCESS1-3_rcp45_tn_mean_annual.nc\n",
    "files85\n",
    "files45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR RCP 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting arrays by periods of time and percentiles with Xclim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsEns45= ens.create_ensemble(files45)\n",
    "dsEns45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mapping data - 30 year means\n",
    "tmp145 = dsEns45.sel(time=(dsEns45.time.dt.year>=1981))\n",
    "window = 30\n",
    "time145 = tmp145.time[0::window]\n",
    "\n",
    "ds30yavg45 = tmp145.coarsen(time=window).mean()\n",
    "ds30yavg45['time'] = time145\n",
    "perc30yavg45 = ens.ensemble_percentiles(ds30yavg45)\n",
    "perc30yavg45 # entire grid\n",
    "\n",
    "# Mapping data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df45 = perc30yavg45.drop('realization').to_dataframe().dropna()\n",
    "\n",
    "df45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform in Celsius and round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df45C = df45.copy()\n",
    "df45C[var+\"_p10\"] = round(df45C[var+\"_p10\"] -273.15,2)\n",
    "df45C[var+\"_p50\"] = round(df45C[var+\"_p50\"] -273.15,2)\n",
    "df45C[var+\"_p90\"] = round(df45C[var+\"_p90\"] -273.15,2)\n",
    "\n",
    "df45C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate 2011, Pivot Table and Create new columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Region1i45 = df45C.reset_index()\n",
    "print (Region1i45)\n",
    "Region1i245 = Region1i45[Region1i45.time.dt.year!= 2011]\n",
    "print (\"2011 eliminated\")\n",
    "df45f = Region1i245.pivot_table(index=[\"lat\",\"lon\"], columns=\"time\")\n",
    "print (\"DF pivoted\")\n",
    "df45f.columns = [year + \"rcp45_p\"+p\n",
    "                     for p in [\"10\", \"50\", \"90\"]\n",
    "                     for year in [\"hist_\",\"t2050_\", \"t2080_\"]]\n",
    "print(\"Columns renamed\")\n",
    "df45f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR RCP 85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting arrays by periods of time and percentiles with Xclim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsEns85= ens.create_ensemble(files85)\n",
    "dsEns85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Mapping data - 30 year means\n",
    "tmp185 = dsEns85.sel(time=(dsEns85.time.dt.year>=1981))\n",
    "window = 30\n",
    "time185 = tmp185.time[0::window]\n",
    "\n",
    "ds30yavg85 = tmp185.coarsen(time=window).mean()\n",
    "ds30yavg85['time'] = time185\n",
    "perc30yavg85 = ens.ensemble_percentiles(ds30yavg85)\n",
    "perc30yavg85 # entire grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df85 = perc30yavg85.drop('realization').to_dataframe().dropna()\n",
    "df85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform in Celsius and round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df85C = df85.copy()\n",
    "df85C[var+\"_p10\"] = round(df85C[var+\"_p10\"] -273.15,2)\n",
    "df85C[var+\"_p50\"] = round(df85C[var+\"_p50\"] -273.15,2)\n",
    "df85C[var+\"_p90\"] = round(df85C[var+\"_p90\"] -273.15,2)\n",
    "df85C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate 2011, Pivot Table and Create new columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Region1i85 = df85C.reset_index()\n",
    "print (Region1i85)\n",
    "Region1i285 = Region1i85[Region1i85.time.dt.year!= 2011]\n",
    "print (\"2011 eliminated\")\n",
    "df85f = Region1i285.pivot_table(index=[\"lat\",\"lon\"], columns=\"time\")\n",
    "print (\"DF pivoted\")\n",
    "df85f.columns = [year + \"rcp85_p\"+p\n",
    "                     for p in [\"10\", \"50\", \"90\"]\n",
    "                     for year in [\"hist_\",\"t2050_\", \"t2080_\"]]\n",
    "print(\"Columns renamed\")\n",
    "df85f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge df45 and 85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftg = pd.merge(df45f, df85f, on=[\"lat\",\"lon\"])\n",
    "dftg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftg1 = dftg.drop(columns=[\"hist_rcp45_p10\",\"hist_rcp45_p50\", \"hist_rcp45_p90\", \"hist_rcp85_p10\", \"hist_rcp85_p50\", \"hist_rcp85_p90\"])\n",
    "dftgh = dftg[[\"hist_rcp45_p50\", \"hist_rcp85_p50\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftg1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge both hist_50 and get the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftgh[\"hist_p50\"] = round((dftgh[\"hist_rcp45_p50\"]+ dftgh[\"hist_rcp85_p50\"])/2, 2)\n",
    "dftgh2 = dftgh.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftgh3 = dftgh2[[\"lat\", \"lon\", \"hist_p50\"]]\n",
    "dftgh3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge means with the 45 and 85 DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftg_all = pd.merge(dftgh3, dftg1, on=[\"lat\",\"lon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftg_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftg_all.to_feather(\"/home/mlopez/EXEC/Processed data to clip with regions/\"+var+\"_annual.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dftg_all = pd.read_feather(\"/home/mlopez/EXEC/Processed data to clip with regions/\"+var+\"_annual.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftg_all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge complete DF with Polygons for each spatial scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary - regioins: column name, short name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_dict = {\"DDE_STF_20K_REG_FOR_VUE_S\": (\"NM_REG_FOR\", \"RF\"), \n",
    "              \"DDE_STF_20K_UA_PER_VUE_S\": (\"PER_NO_UA\", \"UA\"), \n",
    "              \"DOM_BIO\": (\"NOM\", \"DB\"), \n",
    "              \"REG_ECO\": (\"NOM\", \"RE\"), \n",
    "              \"SDOM_BIO\": (\"NOM\", \"SDB\"), \n",
    "              \"Secteurs_Operations_Regionales\": (\"D_GENERAL\", \"SOR\"), \n",
    "              \"SREG_ECO\": (\"NOM\", \"SRE\"), \n",
    "              \"territoire_guide\": (\"TER_GUIDE\", \"TG\") \n",
    "              }\n",
    "\n",
    "for region, (name, short) in short_dict.items():\n",
    "    print(region, name, short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = { 'BAS-SAINT-LAURENT':\"Bas-Saint-Laurent\", \n",
    "     'SAGUENAY -LAC-SAINT-JEAN': \"Saguenay -Lac-Saint-Jean\",\n",
    "     'CAPITALE-NATIONALE-CHAUDIÈRE-APPALACHES':\"Capitale-Nationale-Chaudiere-Appalaches\",\n",
    "     'MAURICIE-CENTRE-DU-QUÉBEC':'Mauricie-Centre-du-Quebec','OUTAOUAIS':'Outaouais', \n",
    "     'ABITIBI-TEMISCAMINGUE':'Abitibi-Temiscamingue', 'COTE-NORD':'Cote-Nord',\n",
    "     'NORD-DU-QUEBEC':'Nord-Du-Quebec', 'GASPESIE-ILES-DE-LA-MADELEINE':'Gaspesie-Iles-De-La-Madeleine', \n",
    "     'LANAUDIERE':'Lanaudiere','LAURENTIDES':\"Laurentides\", \n",
    "     \"ESTRIE-MONTÉRÉGIE-LAVAL-MONTRÉAL\":\"Estrie-Monteregie-Laval-Montreal\", \n",
    "     \"é\": \"e\", \"à\": \"a\", \"è\": \"e\", \"ô\" : \"o\", \"ç\":\"c\", \"É\": \"E\", \"È\": \"E\", \"Î\": \"i\", \"Ç\":\"C\" } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region, (name, short) in short_dict.items():\n",
    "    print(region)\n",
    "    dfpolyshape = from_geofeather('/home/mlopez/EXEC/Grids-polygons-regions/Grid-'+region+'.feather')\n",
    "    dftp = pd.merge(dftg_all, dfpolyshape, on=[\"lat\",\"lon\"])\n",
    "    print (\"Merged with polygons\")\n",
    "    listTG = []\n",
    "    for tg in dftp[name].unique().tolist():\n",
    "        df2 = dftp[dftp[name] == tg]\n",
    "        print (tg)\n",
    "        if tg != None:\n",
    "            listTG.append(df2)\n",
    "        #print (listTG)\n",
    "    for df in listTG:\n",
    "        geometry = df[\"geometry\"]\n",
    "        crs = {'init': \"epsg:4326\"}\n",
    "        gdf = GeoDataFrame(df, crs=crs, geometry=geometry)\n",
    "        print (gdf[name].iloc[0])\n",
    "        #Substitute filename accents\n",
    "        gdf.to_file(replace_all(\"/home/mlopez/EXEC/GeoJsonMFFP/\"+gdf[name].iloc[0], d)+\"_\"+var+\"_annual.json\", driver=\"GeoJSON\")\n",
    "    geometry = dftp[\"geometry\"]\n",
    "    crs = {'init': \"epsg:4326\"}\n",
    "    gdf = GeoDataFrame(dftp, crs=crs, geometry=geometry)\n",
    "    gdf.to_file(\"/home/mlopez/EXEC/GeoJsonMFFP/\"+short+\"_\"+var+\"_annual.json\", driver=\"GeoJSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

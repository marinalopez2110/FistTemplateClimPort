{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import processing_netcdf as pcdf\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "import shapely.geometry \n",
    "import numpy as np\n",
    "from shapely import geometry as gmty\n",
    "from geofeather import to_geofeather, from_geofeather\n",
    "import glob\n",
    "import os\n",
    "import pyarrow\n",
    "from xclim import ensembles as ens\n",
    "from xclim import subset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"/scen3/scenario/netcdf/ouranos/portraits-clim-2.0/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"tx_mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable \n",
    "variable85=\"rcp85_\"+var+\"_seasonal\"\n",
    "variable45=\"rcp45_\"+var+\"_seasonal\"\n",
    "#variable=\"rcp[48]5_tg_mean_annual\"\n",
    "\n",
    "files85 = glob.glob(folder+\"*\"+variable85+\".nc\")\n",
    "files45 = glob.glob(folder+\"*\"+variable45+\".nc\")\n",
    "#ex: ACCESS1-3_rcp45_tn_mean_annual.nc\n",
    "files85\n",
    "files45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR RCP 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting arrays by periods of time with Xclim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsEns45= ens.create_ensemble(files45)\n",
    "dsEns45.time.dt.season[0:4]\n",
    "# Seasonal example 30 y means\n",
    "listds = []\n",
    "i=0\n",
    "for s in dsEns45.time.dt.season[0:4]:\n",
    "    print (i)\n",
    "    tmp1 = dsEns45.sel(time=(dsEns45.time.dt.year>=1981))\n",
    "    tmp1 = tmp1.sel(time=(tmp1.time.dt.season==s))\n",
    "    #print(tmp1)\n",
    "    i = i+1\n",
    "    listds.append(tmp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop to create all 4 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "df45list = []\n",
    "for ds in listds:\n",
    "    print (\"Dataset number: \", i, \"--------------\")\n",
    "    perc45 = ens.ensemble_percentiles(ds)\n",
    "    print (\"Percentiles Obteined\")\n",
    "    df45 = perc45.to_dataframe()\n",
    "    df452 = df45.reset_index()\n",
    "    df453 = df452.loc[df452[\"realization\"] == 0].dropna()\n",
    "    print (\"Converted to DF\")\n",
    "    year_groups = {y:0 for y in range(1980,2011)}\n",
    "    year_groups.update({y:1 for y in range(2041,2071)})\n",
    "    year_groups.update({y:2 for y in range(2071,2101)})\n",
    "    dfp = df453.groupby([df453.time.dt.year.map(year_groups), \"lat\",\"lon\", \"realization\"]).mean()\n",
    "    dfp452 =  dfp.reset_index()\n",
    "    print (\"Split in 3 different time periods\")\n",
    "    df45C = dfp452.copy()\n",
    "    df45C[var+\"_p10\"] = round(df45C[var+\"_p10\"] -273.15,2)\n",
    "    df45C[var+\"_p50\"] = round(df45C[var+\"_p50\"] -273.15,2)\n",
    "    df45C[var+\"_p90\"] = round(df45C[var+\"_p90\"] -273.15,2)\n",
    "    print (\"Transformed in Celsiuds and rounded\")\n",
    "    Region1i45 = df45C.drop(columns=[\"realization\"])\n",
    "    print (\"pivoted\")\n",
    "    df45f = Region1i45.pivot_table(index=[\"lat\",\"lon\"], columns=\"time\")\n",
    "    print (\"DF pivoted\")\n",
    "    if i== 0: season = \"winter\" \n",
    "    elif i == 1: season = \"spring\"\n",
    "    elif i == 2: season = \"summer\"\n",
    "    elif i == 3: season = \"fall\"\n",
    "    print (season)\n",
    "    df45f.columns = [season + \"_\" + year + \"rcp45_p\"+p\n",
    "                     for p in [\"10\", \"50\", \"90\"]\n",
    "                     for year in [\"hist_\",\"t2050_\", \"t2080_\"]]\n",
    "    print(\"Columns renamed\")\n",
    "    df45list.append(df45f)\n",
    "    print (\"DF added to the list\")\n",
    "    i = i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df45list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfw45 = df45list[0].reset_index()\n",
    "dfsp45 = df45list[1].reset_index()\n",
    "dfsu45 = df45list[2].reset_index()\n",
    "dff45 = df45list[3].reset_index()\n",
    "\n",
    "mkey = [\"lat\",\"lon\"]\n",
    "dfse45 = dfw45.merge(dfsp45, on=mkey).merge(dfsu45, on=mkey).merge(dff45, on=mkey)\n",
    "dfse45.to_feather(\"/home/mlopez/EXEC/Processed data to clip with regions/rcp45\"+var+\"_seasonal.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfse452 = dfse45.drop(columns=[\"winter_hist_rcp45_p10\",\"winter_hist_rcp45_p50\", \"winter_hist_rcp45_p90\", \n",
    "                               \"spring_hist_rcp45_p10\", \"spring_hist_rcp45_p50\", \"spring_hist_rcp45_p90\", \n",
    "                               \"summer_hist_rcp45_p10\",\"summer_hist_rcp45_p50\", \"summer_hist_rcp45_p90\", \n",
    "                               \"fall_hist_rcp45_p10\",\"fall_hist_rcp45_p50\", \"fall_hist_rcp45_p90\"])\n",
    "dfse452\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsew = dfse45[[\"winter_hist_rcp45_p50\"]]\n",
    "dfsesp = dfse45[[\"spring_hist_rcp45_p50\"]]\n",
    "dfsesu = dfse45[[\"summer_hist_rcp45_p50\"]]\n",
    "dfsefa = dfse45[[\"fall_hist_rcp45_p50\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOR RCP 85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting arrays by periods of time with Xclim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsEns85= ens.create_ensemble(files85)\n",
    "dsEns85.time.dt.season[0:4]\n",
    "# Seasonal example 30 y means\n",
    "listds85 = []\n",
    "i=0\n",
    "for s in dsEns85.time.dt.season[0:4]:\n",
    "    print (i)\n",
    "    tmp1 = dsEns85.sel(time=(dsEns85.time.dt.year>=1981))\n",
    "    tmp1 = tmp1.sel(time=(tmp1.time.dt.season==s))\n",
    "    print(tmp1)\n",
    "    i = i+1\n",
    "    listds85.append(tmp1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop to create all 4 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "df85list = []\n",
    "for ds in listds85:\n",
    "    print (\"Dataset number: \", i)\n",
    "    perc85 = ens.ensemble_percentiles(ds)\n",
    "    print (\"Percentiles Obteined\")\n",
    "    df85 = perc85.to_dataframe()\n",
    "    df852 = df85.reset_index()\n",
    "    df853 = df852.loc[df852[\"realization\"] == 0].dropna()\n",
    "    print (\"Converted to DF\")\n",
    "    year_groups = {y:0 for y in range(1980,2011)}\n",
    "    year_groups.update({y:1 for y in range(2041,2071)})\n",
    "    year_groups.update({y:2 for y in range(2071,2101)})\n",
    "    dfp = df853.groupby([df853.time.dt.year.map(year_groups), \"lat\",\"lon\", \"realization\"]).mean()\n",
    "    dfp852 =  dfp.reset_index()\n",
    "    print (\"Split in 3 different time periods\")\n",
    "    df85C = dfp852.copy()\n",
    "    df85C[var+\"_p10\"] = round(df85C[var+\"_p10\"] -273.15,2)\n",
    "    df85C[var+\"_p50\"] = round(df85C[var+\"_p50\"] -273.15,2)\n",
    "    df85C[var+\"_p90\"] = round(df85C[var+\"_p90\"] -273.15,2)\n",
    "    print (\"Transformed in Celsiuds and rounded\")\n",
    "    Region1i85 = df85C.drop(columns=[\"realization\"])\n",
    "    print (\"pivoted\")\n",
    "    df85f = Region1i85.pivot_table(index=[\"lat\",\"lon\"], columns=\"time\")\n",
    "    print (\"DF pivoted\")\n",
    "    if i== 0: season = \"winter\" \n",
    "    elif i == 1: season = \"spring\"\n",
    "    elif i == 2: season = \"summer\"\n",
    "    elif i == 3: season = \"fall\"\n",
    "    print (season)\n",
    "    df85f.columns = [season + \"_\" + year + \"rcp85_p\"+p\n",
    "                     for p in [\"10\", \"50\", \"90\"]\n",
    "                     for year in [\"hist_\",\"t2050_\", \"t2080_\"]]\n",
    "    print(\"Columns renamed\")\n",
    "    df85list.append(df85f)\n",
    "    print (\"DF added to the list\")\n",
    "    i = i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df85list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfw85 = df85list[0].reset_index()\n",
    "dfsp85 = df85list[1].reset_index()\n",
    "dfsu85 = df85list[2].reset_index()\n",
    "dff85 = df85list[3].reset_index()\n",
    "mkey = [\"lat\",\"lon\"]\n",
    "dfse85 = dfw85.merge(dfsp85, on=mkey).merge(dfsu85, on=mkey).merge(dff85, on=mkey)\n",
    "dfse85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfse85.to_feather(\"/home/mlopez/EXEC/Processed data to clip with regions/rcp85\"+var+\"_seasonal.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge df45 and 85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfse852 = dfse85.drop(columns=[\"winter_hist_rcp85_p10\",\"winter_hist_rcp85_p50\", \"winter_hist_rcp85_p90\", \n",
    "                               \"spring_hist_rcp85_p10\", \"spring_hist_rcp85_p50\", \"spring_hist_rcp85_p90\", \n",
    "                               \"summer_hist_rcp85_p10\",\"summer_hist_rcp85_p50\", \"summer_hist_rcp85_p90\", \n",
    "                               \"fall_hist_rcp85_p10\",\"fall_hist_rcp85_p50\", \"fall_hist_rcp85_p90\"])\n",
    "dfse852\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting historic mean for each season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function\n",
    "def mean_season(season, dfse45, dfse85):\n",
    "    dfw45 = dfse45[[\"lat\", \"lon\", season+\"_hist_rcp45_p50\"]]\n",
    "    dfw85 = dfse85[[\"lat\", \"lon\", season+\"_hist_rcp85_p50\"]]\n",
    "    dfsew = pd.merge(dfw45, dfw85, on=[\"lat\",\"lon\"])\n",
    "    dfsew[season+\"_hist_p50\"] = round((dfsew[season+\"_hist_rcp45_p50\"]+ dfsew[season+\"_hist_rcp85_p50\"])/2, 2)\n",
    "    dftgwh2 = dfsew.reset_index()\n",
    "    dftgwh3 = dftgwh2[[\"lat\", \"lon\", season+\"_hist_p50\"]]\n",
    "    return (dftgwh3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winter historic mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftgwh = mean_season(\"winter\", dfse45, dfse85)\n",
    "dftgwh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spring historic mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftsph = mean_season(\"spring\", dfse45, dfse85)\n",
    "dftsph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summer historic mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftsuh = mean_season(\"summer\", dfse45, dfse85)\n",
    "dftsuh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fall historic mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftfah = mean_season(\"fall\", dfse45, dfse85)\n",
    "dftfah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge means with the 45 and 85 DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftgseall = dfse852.merge(dfse452, on=mkey).merge(dftfah, on=mkey).merge(dftsuh, on=mkey).merge(dftsph, on=mkey).merge(dftgwh, on=mkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftgseall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftgseall.to_feather(\"/home/mlopez/EXEC/Processed data to clip with regions/\"+var+\"_seasonal.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dftgseall = pd.read_feather(\"/home/mlopez/EXEC/Processed data to clip with regions/\"+var+\"_annual.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge complete DF with Polygons for each spatial scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary - regions: column name, short name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_dict = {\"DDE_STF_20K_REG_FOR_VUE_S\": (\"NM_REG_FOR\", \"RF\"), \n",
    "            \"DDE_STF_20K_UA_PER_VUE_S\": (\"PER_NO_UA\", \"UA\"), \n",
    "              \"DOM_BIO\": (\"NOM\", \"DB\"), \n",
    "              \"REG_ECO\": (\"NOM\", \"RE\"), \n",
    "              \"SDOM_BIO\": (\"NOM\", \"SDB\"), \n",
    "              \"Secteurs_Operations_Regionales\": (\"D_GENERAL\", \"SOR\"), \n",
    "              \"SREG_ECO\": (\"NOM\", \"SRE\"),  \n",
    "              \"territoire_guide\": (\"TER_GUIDE\", \"TG\") \n",
    "              }\n",
    "\n",
    "for region, (name, short) in short_dict.items():\n",
    "    print(region, name, short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = { 'BAS-SAINT-LAURENT':\"Bas-Saint-Laurent\", \n",
    "     'SAGUENAY -LAC-SAINT-JEAN': \"Saguenay -Lac-Saint-Jean\",\n",
    "     'CAPITALE-NATIONALE-CHAUDIÈRE-APPALACHES':\"Capitale-Nationale-Chaudiere-Appalaches\",\n",
    "     'MAURICIE-CENTRE-DU-QUÉBEC':'Mauricie-Centre-du-Quebec','OUTAOUAIS':'Outaouais', \n",
    "     'ABITIBI-TEMISCAMINGUE':'Abitibi-Temiscamingue', 'COTE-NORD':'Cote-Nord',\n",
    "     'NORD-DU-QUEBEC':'Nord-Du-Quebec', 'GASPESIE-ILES-DE-LA-MADELEINE':'Gaspesie-Iles-De-La-Madeleine', \n",
    "     'LANAUDIERE':'Lanaudiere','LAURENTIDES':\"Laurentides\", \n",
    "     \"ESTRIE-MONTÉRÉGIE-LAVAL-MONTRÉAL\":\"Estrie-Monteregie-Laval-Montreal\", \n",
    "     \"é\": \"e\", \"É\": \"E\", \"à\": \"a\", \"è\": \"e\", \"Î\": \"i\", \"È\": \"E\", \"ô\" : \"o\", \"Ç\":\"C\", \"ç\":\"c\",\n",
    "       } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region, (name, short) in short_dict.items():\n",
    "    print(region)\n",
    "    dfpolyshape = from_geofeather('/home/mlopez/EXEC/Grids-polygons-regions/Grid-'+region+'.feather')\n",
    "    dftp = pd.merge(dftgseall, dfpolyshape, on=[\"lat\",\"lon\"])\n",
    "    print (\"Merged with polygons\")\n",
    "    listTG = []\n",
    "    for tg in dftp[name].unique().tolist():\n",
    "        df2 = dftp[dftp[name] == tg]\n",
    "        print (tg)\n",
    "        if tg != None:\n",
    "            listTG.append(df2)\n",
    "        #print (listTG)\n",
    "    for df in listTG:\n",
    "        geometry = df[\"geometry\"]\n",
    "        crs = {'init': \"epsg:4326\"}\n",
    "        gdf = GeoDataFrame(df, crs=crs, geometry=geometry)\n",
    "        print (gdf[name].iloc[0])\n",
    "        #Substitute filename accents\n",
    "        gdf.to_file(replace_all(\"/home/mlopez/EXEC/GeoJsonMFFP/\"+gdf[name].iloc[0], d)+\"_\"+var+\"_seasonal.json\", driver=\"GeoJSON\")\n",
    "    geometry = dftp[\"geometry\"]\n",
    "    crs = {'init': \"epsg:4326\"}\n",
    "    gdf = GeoDataFrame(dftp, crs=crs, geometry=geometry)\n",
    "    gdf.to_file(\"/home/mlopez/EXEC/GeoJsonMFFP/\"+short+\"_\"+var+\"_seasonal.json\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
